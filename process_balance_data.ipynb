{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data to Torch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "from get_label import get_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/medium/\"\n",
    "with open(data_dir + \"train_all.json\") as f:\n",
    "    train_data = json.load(f)\n",
    "with open(data_dir + \"test_all.json\") as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "json_dir = \"./json/\"\n",
    "with open(json_dir + \"word2color.json\") as f:\n",
    "    word2color = json.load(f)\n",
    "with open(json_dir + \"color2label.json\") as f:\n",
    "    color2label = json.load(f)\n",
    "# with open(json_dir + \"friend_label.json\") as f:\n",
    "#     friend_label = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_packed = {}\n",
    "for subdict in train_data.values():\n",
    "    for subsubdict in subdict['imgs_tags']:\n",
    "        train_data_packed.update(subsubdict)\n",
    "train_data_packed = list(train_data_packed.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.PILToTensor()\n",
    "])\n",
    "\n",
    "img_tensor_all = None\n",
    "img_tensor_sub = None\n",
    "label_tensor_all = None\n",
    "first = True\n",
    "sub_first = True\n",
    "label_first = True\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "minibatch = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## takes about 30min to process 156403 labels ########\n",
    "for i, (picdir, word) in enumerate(train_data_packed):\n",
    "    label = get_label(word, word2color, color2label)\n",
    "    if label==-1:\n",
    "        continue\n",
    "    label = torch.tensor([label], dtype=torch.int64)\n",
    "\n",
    "    if label_first:\n",
    "        label_tensor_all = label\n",
    "    else:\n",
    "        label_tensor_all = torch.cat((label_tensor_all, label), 0)\n",
    "    label_first = False\n",
    "\n",
    "    img = Image.open(data_dir + 'train/' + picdir[0:12] + '/' + picdir)\n",
    "    img_tensor = transform(img.resize((224,224))).reshape(1,3,224,224)\n",
    "\n",
    "    if sub_first:\n",
    "        img_tensor_sub = img_tensor\n",
    "    else:\n",
    "        img_tensor_sub = torch.cat((img_tensor_sub, img_tensor), 0)\n",
    "    sub_first = False\n",
    "    \n",
    "    if i == len(train_data_packed)-1 or (i % minibatch) == minibatch-1:\n",
    "        if first:\n",
    "            img_tensor_all = img_tensor_sub\n",
    "        else:\n",
    "            img_tensor_all = torch.cat((img_tensor_all, img_tensor_sub), 0)\n",
    "        first = False\n",
    "        sub_first = True\n",
    "        et = time.time()\n",
    "        print('complete%d, %d s'%(i+1, int(et-st)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(img_tensor_all, '../tensor_data/train_img.pt')\n",
    "torch.save(label_tensor_all, '../tensor_data/train_label.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_samples = {\n",
    "    0: 17000,\n",
    "    12: 14000,\n",
    "    1: 13000,\n",
    "    6: 13000,\n",
    "    3: 12000,\n",
    "    4: 11000,\n",
    "    8: 10000,\n",
    "    2: 10000,\n",
    "    10: 8000,\n",
    "    7: 7000,\n",
    "    13: 7000,\n",
    "    5: 7000,\n",
    "    11: 5000,\n",
    "    9: 3800,\n",
    "}\n",
    "\n",
    "def sample(all_idx, num_samples):\n",
    "    samples = torch.randperm(len(all_idx))[:num_samples]\n",
    "    return all_idx[samples]\n",
    "\n",
    "\n",
    "img_tensor_all_balanced = None\n",
    "img_tensor_sub_balanced = None\n",
    "label_tensor_all_balanced = None\n",
    "label_tensor_sub_balanced = None\n",
    "first = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in range(13):\n",
    "    all_idx = (label_tensor_all==label).nonzero()\n",
    "    if (all_idx.shape[0] >= target_samples[label]): # downsample\n",
    "        sample_idx = sample(all_idx, target_samples[label])\n",
    "        img_tensor_sub_balanced = img_tensor_all[sample_idx]\n",
    "        label_tensor_sub_balanced = label_tensor_all[sample_idx]\n",
    "    else: # duplicate more samples\n",
    "        sample_idx = sample(all_idx, target_samples[label]-all_idx.shape[0])\n",
    "        img_tensor_sub_balanced = torch.cat((img_tensor_all[all_idx], img_tensor_all[sample_idx]), 0)\n",
    "        label_tensor_sub_balanced = torch.cat((label_tensor_all[all_idx], label_tensor_all[sample_idx]), 0)\n",
    "    if first:\n",
    "        img_tensor_all_balanced = img_tensor_sub_balanced\n",
    "        label_tensor_all_balanced = label_tensor_sub_balanced\n",
    "    else:\n",
    "        img_tensor_all_balanced = torch.cat((img_tensor_all_balanced, img_tensor_sub_balanced), 0)\n",
    "        label_tensor_all_balanced = torch.cat((label_tensor_all_balanced, label_tensor_sub_balanced), 0)\n",
    "    first = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(img_tensor_all_balanced, '../tensor_data/train_img_balanced.pt')\n",
    "torch.save(label_tensor_all_balanced, '../tensor_data/train_label_balanced.pt')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "06dd0288bd3f36c7cb8de67987f2766caa96a781a5e5cf66ded4d19c89cb113b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
